\chapter{Proof-of-Concept}%
\label{ch:poc}
Voor het eerste praktische deel van deze bachelorproef werden er drie virtuele machines opgezet binnen VirtualBox met behulp van Vagrant om een gecontroleerde testomgeving te creëren. Deze virtuele machines (VM’s) simuleren een scenario waarin een ransomware-aanval gericht wordt op databases die door het bedrijf worden beheerd. Het primaire doel van deze simulatie is aan te tonen dat het gebruik van immutable storage een effectieve maatregel kan zijn om belangrijke data te beschermen tegen ransomware-aanvallen.
\subsection{Relevantie van de PoC voor de Azure-omgeving van Forvis Mazars}
De Proof-of-Concept (PoC) in VirtualBox simuleert een ransomware-aanval in een lokale omgeving, gericht op het evalueren van beveiligingsmaatregelen zoals immutable storage. Deze aanpak sluit nauw aan bij de Azure-omgeving van Forvis Mazars, waar databases en back-ups worden beheerd.

De technieken uit de PoC, zoals immutable storage, kunnen direct worden toegepast in Azure via functies zoals immutable blobs in Azure Storage. Dit maakt het mogelijk om gegevens beter te beschermen tegen wijzigingen of verwijdering. Daarnaast biedt de PoC een veilig platform om de impact van een ransomware-aanval te begrijpen en te testen hoe snel en effectief back-ups kunnen worden hersteld, wat een cruciaal aspect is voor de bedrijfscontinuïteit.

Forvis Mazars kan de PoC gebruiken om risico’s te analyseren en beveiligingsoplossingen eerst kleinschalig te testen, alvorens deze op grotere schaal binnen hun cloudinfrastructuur toe te passen. Hiermee helpt de PoC bij het verfijnen en optimaliseren van hun bestaande Azure-back-upstrategie.
\subsection{Technische uitwerking}
Voor het opzetten van de virtuele machines in de Proof-of-Concept (PoC) werd gebruik gemaakt van een Vagrantfile. De Vagrantfile definieert de specificaties en configuraties van de VM’s, zoals geheugen, CPU, netwerkadapters en besturingssysteem. 
\begin{lstlisting}[language=Ruby, caption={Vagrantfile voor drie VM's: Back-up Server, Client, en Attacker}]
Vagrant.configure("2") do |config|

# Primary VM
config.vm.define "primary" do |primary|
primary.vm.box = "ubuntu/jammy64"

primary.vm.network "private_network", ip: "192.168.0.10", virtualbox__intnet: "internal_network"

primary.vm.provider "virtualbox" do |vb|
vb.memory = "2048" 
vb.cpus = 1        
end
end

# Back-up VM
config.vm.define "backup" do |backup|
backup.vm.box = "ubuntu/jammy64"

backup.vm.network "private_network", ip: "192.168.0.20", virtualbox__intnet: "internal_network"

backup.vm.provider "virtualbox" do |vb|
vb.memory = "2048" 
vb.cpus = 1       
end
end

# Attacker VM
config.vm.define "attacker" do |attacker|
attacker.vm.box = "ubuntu/jammy64"

attacker.vm.network "private_network", ip: "192.168.0.30", virtualbox__intnet: "internal_network"

attacker.vm.provider "virtualbox" do |vb|
vb.memory = "1024" 
vb.cpus = 1        
end
end

end
\end{lstlisting}

In de onderstaande tabel worden de specificaties van de drie virtuele machines weergegeven die in de Proof-of-Concept zijn gebruikt. Elke VM heeft een specifieke functie binnen het netwerk. De tabel bevat details over de hoeveelheid toegewezen RAM, het aantal CPU-cores, het gebruikte besturingssysteem, de toegewezen IP-adressen en de configuratie van de netwerkadapter. Deze configuratie zorgt ervoor dat de VM's binnen hetzelfde interne netwerk met elkaar kunnen communiceren, wat essentieel is voor het testen van de ransomware-aanval en de back-upstrategieën.
\begin{longtable}{|l|c|c|c|l|l|}
    \hline
    \textbf{Functie} & \textbf{RAM} & \textbf{CPU Cores} & \textbf{IP} & \textbf{Besturingssysteem} & \textbf{Netwerkadapter} \\ \hline
    Primary server    & 2 GB         & 1                  & 192.168.0.10 & Ubuntu 22.04.5 LTS & NAT + Internal \\ \hline
    Back-up server           & 1 GB         & 1                  & 192.168.0.20 & Ubuntu 22.04.5 LTS & NAT + Internal \\ \hline
    Attacker VM         & 2 GB         & 1                  & 192.168.0.30 & Ubuntu 22.04.5 LTS     & NAT + Internal \\ \hline
    
\caption{Beschrijving van de virtuele machines in de Proof of Concept}
\end{longtable}

De Primary VM stelt een actieve databankserver voor binnen een bedrijfsomgeving. Deze server bevat de operationele data van het bedrijf en vertegenwoordigt de belangrijkste bron die beschermd moet worden tegen dataverlies of aanvallen. 

De Back-up VM fungeert als een back-upserver waarop regelmatig de databankback-ups worden opgeslagen. Deze back-upserver is cruciaal voor bedrijfscontinuïteit en disaster recovery, omdat ze in geval van een aanval of fout de herstelmogelijkheden biedt. 

De Attacker VM vertegenwoordigt een hacker met slechte intenties binnen de testomgeving. Deze machine wordt gebruikt om een ransomware-aanval te simuleren, waarbij de functionaliteit van zowel de Primary VM als de Back-up VM wordt bedreigd. Het doel van deze opstelling is om te demonstreren hoe een back-upstrategie, inclusief technieken zoals immutable storage, een bedrijf kan beschermen tegen de gevolgen van een dergelijke aanval.
\subsubsection{Aanmaken van de database}
Op de primary VM werd een eenvoudige SQL-database geïnstalleerd en de volgende tabel aangemaakt om als testdata te dienen:
\begin{lstlisting}[language=SQL, caption={MySQL-code voor het aanmaken van de testdatabank}]
CREATE TABLE employees (
    id INT AUTO_INCREMENT PRIMARY KEY,
    name VARCHAR(50),
    role VARCHAR(50)
);
INSERT INTO employees (name, role) VALUES 
    ('Alice', 'Engineer'), 
    ('Bob', 'Manager'), 
    ('Charlie', 'Analyst');
\end{lstlisting}



\subsubsection{Back-up van de database}
Nadien werd de database geëxporteerd naar een \texttt{.sql}-bestand met het volgende \texttt{mysqldump}-commando:
\begin{lstlisting}[language=script, caption={mysqldump commando om een databank te exporteren}]
mysqldump -u testuser -p testdb > /home/vagrant/backup.sql
\end{lstlisting}
Het resulterende bestand, \texttt{backup.sql}, werd vervolgens met BorgBackup opgeslagen in een back-uprepository op de back-up VM. De repository werd vooraf geïnitialiseerd met het volgende commando:
\begin{lstlisting}[language=script, caption={Borg commando om een map te initialiseren als Borg repository}]
borg init --encryption=repokey /home/vagrant/backups
\end{lstlisting}
Vervolgens werd de back-up gemaakt:
\begin{lstlisting}[language=script, caption={Borg commando om een back-up te nemen}]
borg create --progress 
ssh://vagrant@192.168.0.20/home/vagrant/backups::backup-$(date +%Y-%m-%d) 
/home/vagrant/backup.sql
\end{lstlisting}

\subsubsection{Beveiliging van de back-updirectory}
Om de back-updirectory ransomware-resistent te maken, werd het Linux-commando \texttt{chattr} gebruikt om het \textit{immutable}-attribuut toe te passen op de back-updirectory. Dit attribuut zorgt ervoor dat er geen wijzigingen aan de bestanden in de directory gebeuren, zelfs door gebruikers met \texttt{root}-rechten. Het commando:
\begin{lstlisting}[language=script, caption={Linux commando om de map immutable te maken}]
sudo chattr +i /home/vagrant/backups/
\end{lstlisting}

\subsubsection{Simulatie van de ransomware-aanval}
Op de attacker VM werd een script gebruikt om de ransomware-aanval te simuleren. Het script probeert alle bestanden in de back-updirectory te hernoemen door \texttt{.malware} toe te voegen aan de bestandsnamen. Dit zou overeenkomen met een ransomware-aanval waarbij de back-up bestanden geëncrypteerd worden. Het script is hieronder weergegeven:
\begin{lstlisting}[language=script, caption={Bash script om een ransomware-aanval na te bootsen}]
#!/bin/bash
    
BACKUP_DIR="/home/vagrant/backups"
    
for file in "$BACKUP_DIR"/*; do
  if [ -f "$file" ]; then
    if mv "$file" "${file}.malware"; then
      echo "Renamed $file to ${file}.malware"
    else      
      echo "Error: Could not rename $file"    
    fi    
  fi    
done    
\end{lstlisting}
Voor het gemak heeft de Attacker VM volledige controle gekregen over de Back-up VM. Dit is gedaan omdat de scope van deze bachelorproef niet is om toegang te verkrijgen tot een server, maar eerder om een gecontroleerde omgeving te creëren waarin een Attacker VM een ransomware-aanval nabootst. Het doel is te demonstreren hoe de ransomware zich verspreidt naar de back-up directory, en niet om de daadwerkelijke methoden voor het verkrijgen van toegang tot een server in detail uit te werken.

Toen dit script werd uitgevoerd op de back-up VM, werd duidelijk dat het hernoemen van de bestanden niet lukte vanwege het immutable-attribuut. Dit toont aan dat de ransomware-aanval niet slaagde en de bestanden in de back-updirectory beschermd bleven.

\subsubsection{Herstellen van de back-ups}
Om te bewijzen dat de back-ups nog steeds bruikbaar waren, werd een herstelproces uitgevoerd op de primary VM vanuit de Borg-repository:
\begin{lstlisting}[language=script, caption={Borg commando om een back-up te herstellen}]
borg extract 
ssh://vagrant@192.168.0.20/home/vagrant/backups::backup-2024-12-05
\end{lstlisting}

De databank werd opnieuw opgezet vanuit het bestand dat uit de Borg-repository werd gehaald met het volgende commando:
\begin{lstlisting}[language=script, caption={MySQL commando om een databank te herstellen vanuit een .sql-bestand}]
mysql -u root -p restored_db < /home/vagrant/backup.sql
\end{lstlisting}
De back-up werd gebruikt om de database te herstellen en te controleren. Het herstelproces verliep succesvol, wat bewijst dat de immutable storage de integriteit van de back-ups had behouden en dat de bestanden veilig waren gebleven ondanks de ransomware-aanval.

\newpage
\subsection{Implementatie van immutable storage in de Azure-omgeving}
\subsubsection{Aanmaken van een storage account}
De eerste stap in het implementeren van Immutable Storage in Azure is het aanmaken van een \texttt{Storage Account} in de Azure Portal. 
\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}    
    \includegraphics[width=0.8\textwidth]{img/1imm.png}
    \caption{Storage account zoekopdracht binnen de Azure Portal}
\end{figure}
Bij het aanmaken van het storage account kiezen we de correcte resource group, naam die het account moet krijgen, regio en bij redundancy kiezen we voor \texttt{Locally-redundant storage (LRS)}. Bij de optie \texttt{Account kind} kiezen we voor \texttt{General-purpose v2}, omdat deze versie alle benodigde functionaliteit biedt, zoals het ondersteunen van de blob storage en het configureren van immutability policies. 
\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}    
    \includegraphics[width=0.8\textwidth]{img/3.1imm.png}
    \caption{Configuratie voor het nieuwe storage account}
\end{figure}
\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}    
    \includegraphics[width=0.8\textwidth]{img/3.2imm.png}
    \caption{Tweede deel van de configuratie voor het nieuwe storage account}
\end{figure}
\newpage
\subsubsection{Aanmaken van een container binnen het storage account}
Na het aanmaken van het storage account moet er een container geconfigureerd worden binnen het nieuwe storage account om de gegevens op te slaan. Bij het aanmaken van de container moet de \texttt{public access level} op private staan voor de veiligheid. Containers in Azure werken als mappen waarin je blobs kunt opslaan zoals back-ups.
\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}    
    \includegraphics[width=0.8\textwidth]{img/4imm.png}
    \caption{Configuratie voor de container in het storage account}
\end{figure}
\subsubsection{Opzetten van een time-based retention policy}
Nadien moet er een immutability policy opgezet worden. Hierbij werd gekozen voor een time-based retention policy van 90 dagen, de back-up is met andere woorden bescherm tegen verwijdering of wijziging voor deze periode. Dit is een veilige en praktische keuze voor back-ups. Daarnaast is er bij de optie \texttt{ Allow protected append writes to } gekozen voor \texttt{ Block and append blobs}, dit maakt het mogelijk om gegevens te blijven toevoegen aan de blob zonder de bestaande gegevens te wijzigen of te verwijderen, wat ideaal is voor scenario's zoals logbestanden of incrementele back-ups.
\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}    
    \includegraphics[width=0.8\textwidth]{img/6imm.png}
    \caption{Configuratie voor time-based retention policy}
\end{figure}
\newpage
\subsubsection{Testen van de immmutable storage}
Om de immutable storage te testen is er gekozen om een back-up van een MySQL-database de uploaden naar de container. Na het uploaden van het bestand was er geen optie om dit bestand te verwijderen of te wijzigen. Met andere woorden is deze back-up dus beschermd tegen een ransomware-aanval.
\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}    
    \includegraphics[width=0.8\textwidth]{img/7imm.png}
    \caption{Uploaden van het back-up bestand van de MySQL-databank}
\end{figure}
\begin{figure}[h]
    \centering
    \captionsetup{justification=centering}    
    \includegraphics[width=0.8\textwidth]{img/8imm.png}
    \caption{Screenshot van de poging om het bestand te verwijderen, waarbij de actie wordt geblokkeerd}
\end{figure}
\subsubsection{Conclusie}
De implementatie van immutable storage op het azure storage account is succesvol afgerond, waardoor de opgeslagen back-ups nu beschermd zijn tegen onverwachte wijzigingen of verwijderingen. Daarnaast worden er dagelijks automatische back-ups van de databanken genomen, welke een retentieperiode van 7 dagen hebben. Dit zorgt ervoor dat er altijd een versie van de back-up beschikbaar is, zelfs als de meest recente back-up beschadigd of onbruikbaar blijkt. Deze combinatie van immutable storage en versiebeheer versterkt de bescherming tegen dataverlies en maakt het mogelijk om eerdere, werkende back-ups snel te herstellen.


\subsection{Implementatie van de Kubernetes-gebaseerde automatische back-upoplossing}

\subsubsection{Inleiding}
In deze Proof-of-Concept (PoC) wordt een Kubernetes-omgeving ingezet om een schaalbare en geautomatiseerde back-upoplossing te ontwikkelen voor PostgreSQL- en MySQL-databases. Voor testdoeleinden worden de databases lokaal gehost op een Vagrant Virtual Machine (VM), wat een geïsoleerde omgeving biedt voor het opzetten van de back-upworkflow. De productieomgeving van Forvis Mazars maakt echter gebruik van Azure, waardoor de lokale testomgeving het proces simuleert onder vergelijkbare principes.

De back-ups worden uitgevoerd door containers die draaien binnen Kubernetes Pods. Voor deze containers wordt gebruik gemaakt van een op maat gemaakte Docker-image. Deze image bevat een Python-script voor zowel het uitvoeren van de back-ups als het opschonen van verouderde bestanden. Kubernetes automatiseert de back-upworkflow verder met behulp van CronJobs, terwijl opslag wordt beheerd via Persistent Volumes (PV) en Persistent Volume Claims (PVC). Gevoelige gegevens worden beveiligd met Kubernetes Secrets.

\subsubsection{Python-script voor databaseback-ups}
Het Python-script, zie bijlage \ref{sec:python}, is ontworpen om automatisch back-ups te maken van MySQL- en PostgreSQL-databases en biedt tevens functionaliteit om oude back-ups te verwijderen op basis van een ingestelde retentieperiode. Het maakt gebruik van een object-georiënteerde aanpak, waarbij de \texttt{Backup}-klasse de kern van het script vormt. Bij de initialisatie van de klasse worden verschillende parameters ingesteld, waaronder de naam van de database, de gebruikersnaam en het type database (MySQL of PostgreSQL), evenals de locatie van de back-ups. De bestandsnaam voor de back-up wordt dynamisch gegenereerd op basis van de datum en het type database, en krijgt de vorm van \texttt{backup-\{type\}-\{YYYY-MM-DD\}-\{database\_name\}.dump}. Daarnaast worden omgevingsvariabelen gebruikt voor de IP-adressen van de servers waarop de databanken draaien en poorten van zowel MySQL als PostgreSQL, wat zorgt voor een flexibele configuratie van het script.

\begin{lstlisting}[language=Python]
class Backup:
def __init__(self, database_name, database_user, type, backup_dir):
timestr = datetime.datetime.now().strftime('%Y-%m-%d')
self.filename = f'backup-{type}-{timestr}-{database_name}.dump'
self.database_name = database_name
self.database_user = database_user
self.type = type
self.password = None
self.backup_dir = backup_dir
self.hostname_mysql = os.environ.get("HOSTNAME_MYSQL", "192.168.1.62")
self.hostname_psql = os.environ.get("HOSTNAME_PSQL", "192.168.1.62")
self.port_mysql = os.environ.get("PORT_MYSQL", "3306")
self.port_psql = os.environ.get("PORT_PSQL", "5432")
\end{lstlisting}

Een essentieel onderdeel van het script is de \texttt{set\_password}-methode, die het databasewachtwoord uit een omgevingsvariabele haalt. Indien het wachtwoord niet is ingesteld, wordt een waarschuwingsbericht weergegeven en stopt het script om onveilige of onvolledige back-ups te voorkomen. Dit maakt de back-upprocedure veiliger en garandeert dat alleen bevoegde gebruikers toegang hebben tot de databasegegevens.

De \texttt{create\_backup}-methode is verantwoordelijk voor het daadwerkelijk uitvoeren van de back-up. Afhankelijk van het type database wordt ofwel het \texttt{mysqldump}-commando voor MySQL of het \texttt{pg\_dump}-commando voor PostgreSQL uitgevoerd. Bij het maken van een MySQL-back-up wordt het \texttt{mysqldump}-commando gebruikt met de juiste databasegegevens, zoals gebruikersnaam, wachtwoord, hostnaam en poort. Voor PostgreSQL wordt het \texttt{pg\_dump}-commando gebruikt, waarbij de uitvoer in het "custom format" wordt opgeslagen. Beide commando’s worden uitgevoerd via de \texttt{subprocess.run}-functie, die de uitvoer naar een bestand schrijft. Mocht een van de commando's mislukken, dan zorgt de foutafhandeling ervoor dat het script stopt en een foutmelding wordt weergegeven.
\begin{lstlisting}[language=Python]
    def create_backup(self, type):
    # Create a backup of the database.
    
    # Ensure the backup directory exists
    if not os.path.exists(self.backup_dir):
    os.makedirs(self.backup_dir)
    # Prepend the backup directory to the filename
    full_path = os.path.join(self.backup_dir, self.filename)
    
    if type == "MYSQL":
    try:
    cmd = [
    'mysqldump',
    '--single-transaction',
    '-u', self.database_user,
    f'-p{self.password}',
    '-h', self.hostname_mysql,
    '-P', str(self.port_mysql),
    '--no-tablespaces',
    '-B', self.database_name,
    ]
    with open(full_path, 'w') as backup_file:
    result = subprocess.run(cmd, stdout=backup_file, check=True)  # nosec
    if result.returncode != 0:
    logging.warning(f'Command failed. Return code: {result.returncode}')
    exit(1)
    return full_path
    except Exception as e:
    logging.warning(e)
    exit(1)

    elif type == "PSQL":
    try:
    cmd = [
    'pg_dump',
    '-U', self.database_user,
    '-h', self.hostname_psql,
    '-p', str(self.port_psql),
    '-F', 'c',
    '-f', full_path,
    self.database_name
    ]
    result = subprocess.run(cmd, check=True)  # nosec
    if result.returncode != 0:
    logging.warning(f'Command failed. Return code: {result.returncode}')
    exit(1)
    return full_path
    except Exception as e:
    logging.warning(e)
    exit(1)
\end{lstlisting}

Daarnaast bevat het script de \texttt{delete\_old\_backups}-methode, die ervoor zorgt dat oude back-ups automatisch worden verwijderd om opslagruimte te beheren. Het script vergelijkt de wijzigingsdatum van elk bestand in de opgegeven back-updirectory met de huidige datum en verwijdert bestanden die ouder zijn dan de ingestelde retentieperiode. Dit maakt het mogelijk om ongewenste en verouderde back-ups op te schonen, wat belangrijk is voor het beheer van systeembronnen.
\begin{lstlisting}[language=Python]
    @staticmethod
    def delete_old_backups(directory, retention_days):
    """
    Deletes backup files older than the specified retention period.
    """
    now = datetime.datetime.now()
    logging.info(f"Starting cleanup of backups in {directory} with retention period: {retention_days} days")
    for file in os.listdir(directory):
    if file.startswith("backup-") and file.endswith(".dump"):
    file_path = os.path.join(directory, file)
    file_mtime = datetime.datetime.fromtimestamp(os.path.getmtime(file_path))
    age = (now - file_mtime).days
    logging.info(f"Checking file {file_path}: age = {age} days")
    if age >= retention_days:
    try:
    os.remove(file_path)
    logging.info(f"Deleted old backup: {file_path}")
    except Exception as e:
    logging.warning(f"Failed to delete {file_path}: {e}")
    else:
    logging.info(f"File {file_path} is not old enough to delete (age = {age} days).")
\end{lstlisting}

Het script maakt gebruik van uitgebreide logging om de voortgang van de back-up- en opruimprocessen te documenteren. Logging biedt inzicht in de status van de uitgevoerde handelingen, zoals succesvolle back-ups, waarschuwingen voor ontbrekende omgevingsvariabelen, foutmeldingen bij mislukte bewerkingen en informatie over de bestanden die worden gecontroleerd of verwijderd.

Ten slotte wordt het script uitgevoerd vanuit de \texttt{main}-functie, die de ingevoerde argumenten verwerkt en de bijbehorende methoden aanroept. Als een back-up wordt aangevraagd, wordt een instantie van de \texttt{Backup}-klasse gemaakt en worden de methoden \texttt{set\_password} en \texttt{create\_backup} uitgevoerd. Als de gebruiker de optie voor het verwijderen van oude back-ups heeft opgegeven, wordt de statische methode \texttt{delete\_old\_backups} aangeroepen om de oude bestanden te verwijderen. Op deze manier biedt het script een oplossing voor het beheren van back-ups en het efficiënt verwijderen van verouderde back-ups.

\subsubsection{Dockerfile}
Het Dockerfile, zoals weergegeven in bijlage \ref{sec:dockerfile}, is ontworpen om een container te creëren die de benodigde software bevat voor het uitvoeren van de geautomatiseerde back-ups via het eerder besproken Python-script binnen Kubernetes. Het begint met het ophalen van de laatste versie van Ubuntu als basisimage. Vervolgens worden de MySQL- en PostgreSQL-clients geïnstalleerd, samen met Python3 voor het uitvoeren van het script. Het Python-script wordt vanuit de lokale src-map naar de container gekopieerd. Deze Docker-image is uiteindelijk gepushed naar een Docker-account, zodat deze gebruikt kan worden in de Kubernetes-omgeving. Dit Dockerfile biedt de nodige omgeving voor het uitvoeren van de back-ups in de Kubernetes pods.


\subsubsection{Kubernetes cronjobs en werking}
Een Kubernetes Pod is de kleinste uitvoereenheid binnen een Kubernetes-cluster. Elke Pod bevat een of meer containers die een specifieke taak uitvoeren. In dit project wordt een Pod geconfigureerd om:
\begin{itemize}
    \item De back-up van een database uit te voeren.
    \item Data op te slaan in een Persistent Volume.
    \item Gevoelige informatie, zoals wachtwoorden, te beheren via Secrets.
\end{itemize}

Voor elke database (PostgreSQL en MySQL) is een aparte CronJob geconfigureerd. Deze CronJobs maken gebruik van dezelfde Docker-image, maar passen specifieke parameters toe om de juiste database te back-uppen.

Het proces verloopt als volgt:
\begin{enumerate}
    \item De CronJob wordt volgens een gepland tijdschema uitgevoerd.
    \item De CronJob spint een Pod op waarin de container draait die de back-up uitvoert.
    \item De container voert het Python-script uit dat de database-back-up naar een Persistent Volume schrijft.
    \item Na voltooiing wordt de Pod beëindigd, terwijl de back-upbestanden bewaard blijven.
\end{enumerate}

Het eerste CronJob YAML-bestand, dat wordt gepresenteerd in bijlage \ref{sec:cron}.1,  configureert een geautomatiseerde taak die elke nacht om 2 uur een back-up maakt van een MySQL-database. Deze taak wordt uitgevoerd in een Kubernetes-omgeving en maakt gebruik van een container die het eerder genoemde Python-script uitvoert om de back-up te maken. De cronjob is opgezet om periodiek de database te back-uppen zonder menselijke tussenkomst.

De \texttt{apiVersion: batch/v1} en \texttt{kind: CronJob} geven aan dat het bestand een Kubernetes CronJob definieert, een soort geplande taak die op regelmatige tijdstippen wordt uitgevoerd. De \texttt{schedule} is ingesteld op "0 2 * * *", wat betekent dat de back-up elke dag om 2:00 uur 's nachts wordt uitgevoerd. Dit schema volgt de standaard cron-vergelijkingsnotatie, waarbij de tijd en frequentie worden gedefinieerd.

Binnen de \texttt{jobTemplate} wordt de daadwerkelijke taak gespecificeerd die door de cronjob moet worden uitgevoerd. De container die wordt gebruikt voor deze taak is de \texttt{bouzewazi/ubu4} Docker-image, die het Python-script bevat dat verantwoordelijk is voor het maken van de back-up. Het script wordt uitgevoerd met een aantal argumenten, waaronder de database-naam (\texttt{testdb}), gebruikersnaam (\texttt{root}), het type database (\texttt{MYSQL}), en de locatie van de back-up (\texttt{/data}). Dit zorgt ervoor dat de juiste database op het juiste moment wordt geback-upt en de back-up wordt opgeslagen in een gedeelde opslaglocatie.

De container maakt gebruik van een persistent volume claim, gedefinieerd onder \texttt{volumes}, om back-upbestanden op te slaan. Het volume wordt gekoppeld aan een specifieke directory binnen de container via \texttt{volumeMounts}. Dit zorgt ervoor dat de opgeslagen gegevens behouden blijven, zelfs als de container opnieuw wordt opgestart.

Verder wordt het databasewachtwoord veilig doorgegeven via een Kubernetes Secret. Het wachtwoord wordt opgehaald uit een Kubernetes Secret als een environment variable genaamd \texttt{DB\_PASSWORD}. Dit zorgt ervoor dat gevoelige gegevens op een veilige manier aan de container worden verstrekt zonder dat ze hard-coded in de YAML worden opgenomen.

Daarbij is er ook een andere CronJob die dezelfde functionaliteit biedt, maar dan voor het maken van back-ups van een PostgreSQL-database. Deze CronJob is vergelijkbaar met de MySQL CronJob, met aanpassingen die specifiek zijn voor de PostgreSQL-databaseconfiguratie, zoals te zien in bijlage \ref{sec:cron}.2.

Tenslotte is er een CronJob die oude back-ups verwijdert die ouder zijn dan 14 dagen, wat de retentieperiode is voor de dagelijkse back-ups. Dit zorgt ervoor dat alleen back-ups binnen de laatste 14 dagen bewaard blijven, waardoor opslag efficiënt wordt beheerd, zoals beschreven in bijlage \ref{sec:cron}.
\subsection{Relevantie van de Kubernetes-setup voor Forvis Mazars}

De Kubernetes-setup die in deze Proof of Concept (PoC) is ontwikkeld, blijkt direct relevant voor de werkomgeving van Forvis Mazars, aangezien ook daar Kubernetes wordt ingezet voor het beheer van de IT-infrastructuur. In deze sectie worden de overeenkomsten besproken, wordt toegelicht hoe de oplossing aansluit bij de behoeften van Forvis Mazars, en worden mogelijke aanpassingen beschreven om de setup volledig te integreren in hun bestaande workflows. Het belangrijkste verschil is dat bij Forvis Mazars de back-ups niet worden opgeslagen in een Persistent Volume, maar rechtstreeks worden geüpload naar een Azure Storage Container.

\subsubsection*{Overeenkomsten met de Forvis Mazars Setup}

Bij Forvis Mazars wordt gebruikgemaakt van Kubernetes Pods om databases te beheren en back-ups te genereren. De fundamentele componenten van de ontwikkelde oplossing – zoals het gebruik van CronJobs en containerisatie – vertonen sterke overeenkomsten met de gehanteerde methodologie. Enkele concrete parallellen zijn:

\begin{itemize}
    \item \textbf{Automatisering via CronJobs} \\
    Bij zowel de PoC als de setup van Forvis Mazars worden Kubernetes CronJobs toegepast voor het plannen van taken. In de PoC worden deze CronJobs ingezet om dagelijkse back-ups uit te voeren en oudere back-ups automatisch te verwijderen. Deze aanpak wordt gekenmerkt door schaalbaarheid en sluit goed aan bij de architectuur van Kubernetes die door Forvis Mazars wordt gebruikt.
    
    \item \textbf{Beveiliging van wachtwoorden} \\
    In de PoC worden Kubernetes Secrets gebruikt om gevoelige informatie, zoals databasewachtwoorden, door te geven aan het Python-script dat de back-ups uitvoert. Dit zorgt ervoor dat wachtwoorden niet hardcoded hoeven te worden in configuratiebestanden of scripts. Hoewel niet bekend is of Forvis Mazars eveneens Secrets gebruikt, biedt deze aanpak een veilige en flexibele oplossing die eenvoudig kan worden geïntegreerd in een vergelijkbare omgeving.
    
    \item \textbf{Schaalbaarheid en containerisatie} \\
    Het gebruik van een gestandaardiseerde Docker-image voor de uitvoering van de back-ups weerspiegelt de wijze waarop Kubernetes Pods bij Forvis Mazars worden beheerd. Containers kunnen eenvoudig worden aangepast of opnieuw worden ingezet, zonder dat dit aanpassingen aan de volledige infrastructuur vereist.
\end{itemize}


\subsubsection*{Verschil in Back-upopslag}

Het grootste verschil tussen de PoC en de setup van Forvis Mazars ligt in de wijze van back-upopslag. Bij de PoC worden back-ups lokaal opgeslagen in een Persistent Volume (PV), terwijl deze bij Forvis Mazars direct worden geüpload naar een Azure Storage Container. Dit verschil heeft enkele belangrijke implicaties:

\begin{itemize}
    \item \textbf{Opslaglocatie} \\
    Persistent Volumes bieden een eenvoudige manier om gegevens lokaal binnen een Kubernetes-cluster op te slaan. Dit maakt ze geschikt voor testomgevingen en lokale implementaties, zoals in de PoC. Forvis Mazars maakt echter gebruik van een cloudopslagoplossing in de vorm van Azure Storage Containers. Deze oplossing biedt voordelen zoals schaalbaarheid, hoge beschikbaarheid en eenvoud in beheer binnen een productieomgeving.
    
    \item \textbf{Integratie met Azure} \\
    Bij Forvis Mazars wordt de Kubernetes-setup geïntegreerd met Azure door gebruik te maken van tools zoals Azure CLI of SDK’s voor het uploaden van back-ups naar Azure Storage. Binnen de PoC zou een vergelijkbare integratie kunnen worden gerealiseerd door het Python-script aan te passen, zodat back-ups direct naar Azure worden geüpload in plaats van lokaal te worden opgeslagen. Dit kan worden bereikt door de Azure Storage SDK voor Python te implementeren of CLI-opdrachten toe te voegen aan de Docker-image.
\end{itemize}

Door deze overeenkomsten en verschillen te analyseren, kan worden geconcludeerd dat de ontwikkelde Kubernetes-setup een solide basis biedt die volledig kan worden afgestemd op de operationele vereisten van Forvis Mazars.



\subsection{Herstelcapaciteit (Restore from Backup)}
Een belangrijk onderdeel van het praktijkgedeelte van dit onderzoek is het testen van de herstelcapaciteit (restore from back-up). Dit was een essentiële vereiste in het onderzoek, waarbij de focus lag op het efficiënt en snel herstellen van systemen vanuit de back-ups. Het doel was om een idee te krijgen over hoe snel en betrouwbaar een databank up-and-running kan zijn na het ondergaan van een incident.

\subsubsection{Toepassing van de herstelstrategie}
Voor deze must-have heb ik het herstelproces gesimuleerd in een testomgeving waarbij ik back-ups ophaal uit de immutable Azure storage container en deze dan herstel in een MySQL- en PostgreSQL-databank. Deze testomgeving komt grotendeels overeen met de actieve omgeving die Forvis Mazars gebruikt. Het proces omvatte de volgende stappen:

\begin{enumerate}
    \item \textbf{Back-ups ophalen uit de immutable storage in Azure} \\
    De back-ups werden veilig opgeslagen in een Azure Storage Account met een immutable opslagbeleid, wat een cruciale maatregel is tegen ransomware-aanvallen. Door het gebruik van het \texttt{az storage blob download}-commando werden de back-ups gedownload naar de lokale virtuele machine.
    
    \item \textbf{Herstellen van de PostgreSQL- en MySQL-databanken} \\
    Na het downloaden werden de PostgreSQL- en MySQL-databases opnieuw opgezet met herstelcommando’s. Voor PostgreSQL werd het bestand hersteld met \texttt{pg\_restore}, terwijl voor MySQL gebruik werd gemaakt van het \texttt{mysql}-commando. Beide hersteltaken verliepen succesvol en zonder dataverlies. Om aan te tonen dat er geen dataverlies optrad, werd vóór en na het herstel een COUNT(*)-query uitgevoerd in beide databases. De resultaten van deze queries waren identiek, wat bevestigt dat alle rijen correct zijn hersteld en de back-upstrategie betrouwbaar is. Dit hele proces is gemeten en duurde 48 seconden, wat wijst op een snelle toegang tot de back-ups in noodsituaties. Het back-upbestand voor de MySQL-databank had een bestandsgrootte 383 KiB en het bestand voor de PostgreSQL-databank had een grootte van 45,16 KiB. Deze bestanden werden gedownload met een internetsnelheid van 75.33 Mbit/s. Dit is getest met de tool speedtest-cli.
\end{enumerate}

\subsubsection{Link met Herstelcapaciteit}
De testprocedure toont aan dat de opgestelde back-upstrategie niet alleen effectief is in het beschermen van gegevens, maar ook voldoet aan de eisen van herstelcapaciteit:

\begin{itemize}
    \item \textbf{Efficiëntie:} Het herstelproces, vanaf het downloaden van de back-ups tot het opnieuw opzetten van de databases, verliep in een relatief korte tijd. Dit bevestigt dat de back-ups eenvoudig en snel toegankelijk zijn, wat essentieel is in een bedrijfsomgeving waar down-time zo laag mogelijk moet zijn.
    
    \item \textbf{Betrouwbaarheid:} Door gebruik te maken van immutable opslag in Azure worden de back-ups beschermd tegen ongewenste acties en aanvallen, wat de kans op succesvol herstel sterk verhoogt.
\end{itemize}

\subsubsection{Conclusie}
De uitgevoerde tests bieden waardevolle inzichten in de herstelcapaciteit van de back-upstrategie. Het toont aan hoe een goed ontworpen back-upplan bedrijven in staat stelt om snel te reageren op noodsituaties en hun systemen betrouwbaar te herstellen. Hiermee is aangetoond dat het systeem niet alleen beschermt tegen gegevensverlies, maar ook operationeel herstel mogelijk maakt binnen een acceptabele tijd. Dit maakt het een reële oplossing voor bedrijven die ransomware-resistente back-upstrategieën willen implementeren.































